---
title: "Group Project"
author: "field1, field2, field3"
date: "10/6/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#### Read table from GitHub repository ####
cancer_data <-read.csv("https://raw.githubusercontent.com/Doriasamp/M362/main/cancer_DFwCat.csv", header = TRUE)


#### Makes chuncks visible/invisible   ####
#### 1 = visible, 0 = invisible        ####

#### Importan Variables and Vectors    ####
ColumNames <- c("Poverty %","AvgHoushol", "Pvt Cov %", "Incidence", "Median Income $", "Death Rate")

#### Makes chuncks visible/invisible   ####
x <- 0 # 1 = visible, 0 = invisible
#### Color for plots
colplot <-"lightblue4"
```

# Project

```{r , echo=x}
#Find Outliers from boxplot
boxplot(cancer_data$povertyPercent, cancer_data$AvgHouseholdSize, names = ColumNames[1:2], horizontal = TRUE, col = colplot)
boxplot(cancer_data$PctPrivateCoverage,cancer_data$incidenceRate, names = ColumNames[3:4], horizontal = TRUE, col = colplot)
boxplot(cancer_data$medIncome,names = ColumNames[5], horizontal = TRUE, ylab = ColumNames[5],  col = colplot)

```

### Write something about it
We are going to remove outliers



```{r include=FALSE}
#Removing outliers

y <- 0 #turn off outliers graphs, there are too many of them

poverty_out=boxplot(cancer_data$povertyPercent, plot = y)$out
poverty_rows=which(cancer_data$povertyPercent%in%poverty_out)

cd2 = cancer_data[-poverty_rows,]

household_out= boxplot(cd2$AvgHouseholdSize, plot = y)$out
household_rows=which(cd2$AvgHouseholdSize%in%household_out)

cd3 = cd2[-household_rows,]

private_out = boxplot(cd3$PctPrivateCoverage, plot = y)$out
private_rows = which(cd3$PctPrivateCoverage%in%private_out)

cd4 = cd3[-private_rows,]

boxplot(cd4$povertyPercent, plot = y)$out
#11 outliers in poverty percentage after first removal
poverty_out2 = boxplot(cd4$povertyPercent, plot = y)$out
poverty_rows2 = which(cd4$povertyPercent%in%poverty_out2)

cd5 = cd4[-poverty_rows2,]

boxplot(cd4$AvgHouseholdSize, plot = y)$out
#24 outliers in household size after first removal
household_out2 = boxplot(cd4$AvgHouseholdSize, plot = y)$out
household_rows2 = which(cd4$AvgHouseholdSize%in%household_out2)

cd6=cd5[-household_rows2,]

boxplot(cd4$PctPrivateCoverage, plot = y)$out
#0 outliers in private coverage percentage after first removal

boxplot(cd6$povertyPercent, plot = y)$out
#0 outliers in poverty percentage after second removal

boxplot(cd6$AvgHouseholdSize, plot = y)$out
#23 outliers in household size after second removal
household_out3=boxplot(cd6$AvgHouseholdSize, plot = y)$out
household_rows3=which(cd6$AvgHouseholdSize%in%household_out3)

cd7=cd6[-household_rows3,]
dim(cd7)

boxplot(cd7$AvgHouseholdSize, plot = y)$out
#22 outliers in household size after third removal
household_out4 = boxplot(cd7$AvgHouseholdSize, plot = y)$out
household_rows4 = which(cd7$AvgHouseholdSize%in%household_out4)

cd8=cd7[-household_rows4,]

boxplot(cd8$AvgHouseholdSize, plot = y)$out
#0 outliers in household size after fourth removal

income_out=boxplot(cd8$medIncome, plot = y)$out
income_rows=which(cd8$medIncome%in%income_out)

cd9=cd8[-income_rows,]

irate_out = boxplot(cd8$incidenceRate, plot = y)$out
irate_rows = which(cd8$incidenceRate%in%irate_out)

cd10 = cd9[-irate_rows,]

boxplot(cd10$medIncome, plot = y)$out
#14 outliers left after first removal

boxplot(cd10$incidenceRate, plot = y)$out
#82 outliers left after first removal

income_out2 = boxplot(cd10$medIncome, plot = y)$out
income_rows2 = which(cd10$medIncome%in%income_out2)

irate_out2 = boxplot(cd10$incidenceRate, plot = y)$out
irate_rows2 = which(cd10$incidenceRate%in%irate_out2)

cd11 = cd10[-income_rows2,]

cd12 = cd11[-irate_rows2,]

boxplot(cd12$medIncome, plot = y)$out
#1 outlier left after second removal

boxplot(cd12$incidenceRate, plot = y)$out
#84 outliers left after second removal

income_out3 = boxplot(cd12$medIncome, plot = y)$out
income_rows3 = which(cd12$medIncome%in%income_out3)

irate_out3 = boxplot(cd12$incidenceRate, plot = y)$out
irate_rows3 = which(cd12$incidenceRate%in%irate_out3)

cd13=cd12[-income_rows3,]

cd14=cd13[-irate_rows3,]

boxplot(cd14$medIncome, plot = y)$out
#3 outliers left after third removal

boxplot(cd14$incidenceRate, plot = y)$out
#76 outliers left after third removal

income_out4=boxplot(cd14$medIncome, plot = y)$out
income_rows4= which(cd14$medIncome%in%income_out4)

irate_out4 = boxplot(cd14$incidenceRate, plot = y)$out
irate_rows4 = which(cd14$incidenceRate%in%irate_out4)

cd15=cd14[-income_rows4,]

cd16=cd15[-irate_rows4,]

boxplot(cd16$incidenceRate, plot = y)$out
#46 outliers left after fourth removal

boxplot(cd16$medIncome, plot = y)$out
#3 outliers left after fourth removal

irate_out5 = boxplot(cd16$incidenceRate, plot = y)$out
irate_rows5 = which(cd16$incidenceRate%in%irate_out5)

income_out5 = boxplot(cd16$medIncome, plot = y)$out
income_rows5 = which(cd16$medIncome%in%income_out5)

cd17 = cd16[-irate_rows5,]

cd18 = cd17[-income_rows5,]

boxplot(cd18$medIncome, plot = y)$out
#4 outliers left after fifth removal

boxplot(cd18$incidenceRate, plot = y)$out
#10 outliers left afer fifth removal

income_out6 = boxplot(cd18$medIncome, plot = y)$out
income_rows6 = which(cd18$medIncome%in%income_out6)


irate_out6 = boxplot(cd18$incidenceRate, plot = y)$out
irate_rows6 = which(cd18$incidenceRate%in%irate_out6)

cd19=cd18[-income_rows6,]

cd20=cd19[-irate_rows6,]

boxplot(cd20$medIncome, plot = y)$out
#0 outliers remaining after sixth removal

boxplot(cd20$incidenceRate, plot = y)$out
#12 outliers remaining after sixth removal

irate_out7 = boxplot(cd20$incidenceRate, plot = y)$out
irate_rows7 = which(cd20$incidenceRate%in%irate_out7)


cd21=cd20[-irate_rows7,]

boxplot(cd21$incidenceRate, plot = y)$out
#4 outliers left after seventh removal

irate_out8 = boxplot(cd21$incidenceRate, plot = y)$out
irate_rows8 = which(cd21$incidenceRate%in%irate_out8)

cd22=cd21[-irate_rows8,]

boxplot(cd22$incidenceRate, plot = y)$out
#1 outlier left after eigth removal

irate_out9 = boxplot(cd22$incidenceRate, plot = y)$out
irate_rows9 = which(cd22$incidenceRate%in%irate_out9)

cd23=cd22[-irate_rows9,]

boxplot(cd23$incidenceRate, plot = y)$out
#2 outliers left after ninth removal

irate_out10 = boxplot(cd23$incidenceRate, plot = y)$out
irate_rows10 = which(cd23$incidenceRate%in%irate_out10)

cd24=cd23[-irate_rows10,]

boxplot(cd24$incidenceRate, plot = y)$out
#0 outliers left after tenth removal

boxplot(cd24$povertyPercent,cd24$AvgHouseholdSize,cd24$medIncome,
        cd24$incidenceRate,cd24$PctPrivateCoverage, plot = y)$out
#appears there are outliers in poverty, household, and pctPC

boxplot(cd24$povertyPercent, plot = y)$out
#2 outliers in povertyPCT

boxplot(cd24$AvgHouseholdSize, plot = y)$out
#11 outliers in household size

boxplot(cd24$PctPrivateCoverage, plot = y)$out
#1 outlier in pctPC

poverty_out3 = boxplot(cd24$povertyPercent, plot = y)$out
poverty_rows3 = which(cd24$povertyPercent%in%poverty_out3)

household_out5 = boxplot(cd24$AvgHouseholdSize, plot = y)$out
household_rows5 = which(cd24$AvgHouseholdSize%in%household_out5)

private_out2 = boxplot(cd24$PctPrivateCoverage, plot = y)$out
private_rows2 = which(cd24$PctPrivateCoverage%in%private_out2)

cd25=cd24[-poverty_rows3,]

cd26=cd25[-household_rows5,]

cd27=cd26[-private_rows2,]

boxplot(cd27$povertyPercent, plot = y)$out
#0 outliers in povertyPCT


boxplot(cd27$AvgHouseholdSize, plot = y)$out
#11 outliers in household size
#same values as earlier -> check household_out5 for error

boxplot(cd27$PctPrivateCoverage, plot = y)$out
#0 outliers in pctPC

household_out6 = boxplot(cd27$AvgHouseholdSize, plot = y)$out
household_rows6 = which(cd27$AvgHouseholdSize%in%household_out6)

cd28=cd27[-household_rows6,]

boxplot(cd28$AvgHouseholdSize, plot = y)$out
#0 outliers left in average household size

boxplot(cd28$povertyPercent,cd28$AvgHouseholdSize,cd28$medIncome,
        cd28$incidenceRate,cd28$PctPrivateCoverage, plot = y)$out
#all outliers removed from the predictor variables

```



```{r,echo = x}
boxplot(cd28$povertyPercent,cd28$AvgHouseholdSize, names = ColumNames[1:2], horizontal = TRUE, col = colplot)
boxplot(cd28$PctPrivateCoverage,cd28$incidenceRate, names = ColumNames[3:4], horizontal = TRUE, col = colplot)
boxplot(cd28$medIncome, name = ColumNames[5], horizontal = TRUE, col = colplot, ylab = ColumNames[5])

#dataframe renamed for clarity
newcancer_data <- cd28
```
### We removed all of the 447 outliers from dataset!


```{r, echo = x}
### RUN THIS CHUNK ONLY AFTER PRIOR CHUNKS ARE RAN ###
#removes variables we don't need anymore
rm(cancer_data,cd2,cd3,cd4,cd5,cd6,cd7,cd8,cd9,cd10,cd11,cd12,cd13,cd14,cd15,cd16,cd17,cd18,cd19,cd20,cd21,cd22,cd23,cd24,cd25,cd26,cd27,cd28)
```

# Plots between predictors and death rate with their respective correlation coefficients
We need to write something underneath each of the plots


```{r, echo = x}
plot(newcancer_data$povertyPercent,newcancer_data$TARGET_deathRate, xlab = ColumNames[1], ylab = ColumNames[6],col = colplot, pch =16 )
#appears to be a moderate positive linear association
cor(newcancer_data$povertyPercent,newcancer_data$TARGET_deathRate)
# r = 0.4530695
```
### Write something here about this




```{r, echo = x}
plot(newcancer_data$AvgHouseholdSize,newcancer_data$TARGET_deathRate, xlab = ColumNames[2], ylab = ColumNames[6],col = colplot, pch =16)
#appears to be a moderate positive linear association
cor(newcancer_data$AvgHouseholdSize,newcancer_data$TARGET_deathRate)
# r = 0.155252
```
### Write something here about this



```{r, echo = x}
plot(newcancer_data$PctPrivateCoverage,newcancer_data$TARGET_deathRate, xlab = ColumNames[3], ylab = ColumNames[6],col = colplot, pch =16)
#appears to be a moderate positive linear association
cor(newcancer_data$PctPrivateCoverage,newcancer_data$TARGET_deathRate)
# r = -0.4569882
```
### Write something here about this



```{r, echo = x}
plot(newcancer_data$medIncome,newcancer_data$TARGET_deathRate, xlab = ColumNames[4], ylab = ColumNames[6],col = colplot, pch =16)
#appears to be a moderate positive linear association
cor(newcancer_data$medIncome,newcancer_data$TARGET_deathRate)
# r = -0.4461167
```
### Write something here about this



```{r, echo = x}
plot(newcancer_data$incidenceRate,newcancer_data$TARGET_deathRate, xlab = ColumNames[5], ylab = ColumNames[6],col = colplot, pch =16)
#appears to be a moderate positive linear association
cor(newcancer_data$incidenceRate,newcancer_data$TARGET_deathRate)
# r = 0.3519352
```
### Write something here about this

### There are 2154 rows in our dataframe. We have randomly select 80% of rows from our dataframe for a total of 1723 data. Those data are now parts of a Train dataset we will use to perform regression analysis. At the same time we used the remaining 431 data for testing.

### Created two .txt files with data formatted as table. Uploaded on GitHub. This RMarkdown reads data directly from Github repository

```{r, echo = x}
Traincancer_data <-read.table("https://raw.githubusercontent.com/Doriasamp/M362/main/TrainCancerData.txt", header = TRUE)
Testcancer_data <-read.table("https://raw.githubusercontent.com/Doriasamp/M362/main/TestCancerData.txt", header = TRUE)
```

## Now we are creating a multiple linear regression model to predict cancer death rate using our predictors

```{r, echo = x}
model1 <-lm(Traincancer_data$TARGET_deathRate ~ Traincancer_data$povertyPercent + Traincancer_data$AvgHouseholdSize + Traincancer_data$PctPrivateCoverage + Traincancer_data$incidenceRate+Traincancer_data$medIncome +  as.factor(Traincancer_data$Region.CAT.), data = Traincancer_data)
summary.lm(model1, digits = 4, symbolic.cor = TRUE)
```

# Multiple Regression Model: Checking Assumptions

## Check Assumption 1 and 2: Check mean of error is zero, and check that the errors have the same variance given any combination of values of predictors, in doing so we plot residual plots:
```{r, echo = x}
#Errors vs y-hat
plot(model1$fitted.values, model1$residuals);abline(0,0)
#Errors vs predictors
plot(Traincancer_data$povertyPercent, model1$residuals);abline(0,0)
plot(Traincancer_data$AvgHouseholdSize, model1$residuals);abline(0,0)
plot(Traincancer_data$PctPrivateCoverage, model1$residuals);abline(0,0)
plot(Traincancer_data$incidenceRate, model1$residuals);abline(0,0)
plot(Traincancer_data$medIncome, model1$residuals);abline(0,0)
```
### Assumption 1 conclusions: All the above residual plots are approximately symmetric around x-axis. The point look random and not patterns seen. So the assumption  that mean of error is zero is satified.
### Assumption 2 conclusion: All residuals plot have an approximately horizontal band around x axis. therefore we can say that the error variance is constant for all different value combinations of predictors.

## Check Assumption 3: For any given set of predictor variables, the error is normally distributed, thus response variable y is normally distributed as well. We plot the qqnorm graph.
```{r, echo = x}
#Plot qqnorm graph
qqnorm(model1$residuals)
```
### Assumption 3 conclusions: The qqplot of residuals looks approximately linear. Therefore the residuals of the errors are normally distributed.

## Check Assumption 4: The observations of the response variable are independent from one another. Observations are not correlated. We use either the DW test value or the p-value.
```{r, echo = x}
# We nee the lmtestpackage to use the dwtest() function
# load the package 
require(lmtest)
dwtest(model1, alternative = "two.sided")
```
### Assumption 4 conclusions: The p-value is greater than 0.05 (0.9512 > 0.05) so we fail to reject H0: "Independent errors". Therefore we will take the assumption as satisfied.

### We still don't know how to check the 5th assumption: None of the predictors are constant and there are no exact linear relationships among predictors.

### Assuming all the multiple linear regression assumptions are satisfied. We can perform the individual t-test for each individual predictor

```{r, echo = x}
summary(model1)
```
### In the above output we can see that the individual t-values of, 'AvgHouseholdSize', 'PctPrivateCoverage', 'incidenceRate', and 'medIncome' are less than 0.05. So they are useful predictor variables for colGPA
### However, 'povertyPercent' predictor has a value of 0.6, greater than 0.05 so is not a useful predictor variable to predict the death rate.

###Lets create a new model without ACT variable and check which model is better, the one with 'povertyPercent' variable (model1), or the one without ACT variable (model2). We will perform an AIC (Alike Information Criterion) test, where the smaller AIC is preferred.
```{r, echo = x}
model2 = lm(Traincancer_data$TARGET_deathRate ~ Traincancer_data$AvgHouseholdSize +            Traincancer_data$PctPrivateCoverage + Traincancer_data$incidenceRate + Traincancer_data$medIncome, data = Traincancer_data)
AIC(model1)
AIC(model2)
```
### The model 2 has a lower AIC score, therefore we are going to eliminate the 'povertyPercent' predictor variables from our model.
```{r, echo = x}
# pass model 2 under ImprovedModel
ImprovedModel = model2
```


#Check prediction accuracy for the improved model.

###We need first to predict the response variable value using a new dataset, which is the TestCancerData.txt dataset that is in the GitHub repository. Then we will use the MAPE, Mean Absolute Percentage Error (MAPE)

```{r, echo = x}
#When we predict we pass only the predictor variable in the 'Traincancer_data' dataset as a data.frame(). Then the model will predict the response variable value.

# Column16=AvgHouseholdSize, Column26=PctPrivateCoverage, Column4=incidenceRate, Column5=medIncome
#For convenience I'm going to create 2 new data frame for Train and Test where
#the dependent variable is first column and AvgHouseholdSize, PctPrivateCoverage, incidenceRate, 
#and medIncome are respectively the 2nd, 3rd, 4th, and 5th columns
ReducedColTrain = data.frame(Traincancer_data[, c(3,16,26,4,5)])
ReducedColTest = data.frame(Testcancer_data[, c(3,16,26,4,5)])
Header = c("TARGET_deathRate","AvgHouseholdSize","PctPrivateCoverage","incidenceRate","medIncome")
#*****************************************************************************************
PredictDeathRate = predict(ImprovedModel, newdata = ReducedColTest)
#*****************************************************************************************
# Idk why, but I can't make this work, 'PredictDeathRate' it should give me a length equal to
#the length of columns of TestDataset which is 431, instead I'm keeping getting a 1723,
#which is the size of Train. Because of that I cannot perform the cbind and the MAPE because R will try to
#perform operations with vectors of different size.
#*****************************************************************************************

#We can compare the PredictDeathRate with actual DeathRate in the dataset
#################Code with problems because of line 433, blocked by #

#column binding is done by cbind()
#cbind(Predicted = PredictDeathRate, Actual = Testcancer_data$TARGET_deathRate)
#MAPE = (sum(abs((Testcancer_data$TARGET_deathRate - PredictDeathRate)/Testcancer_data$TARGET_deathRate)/nrow(Testcancer_data$TARGET_deathRate)))*100
#MAPE
```   


# Checking MultiCollinearity

#### We are going to follow 4 ways to check multicollinearity

## 1. Using correlation between predictor variables

```{r, echo = x}
#corMatrix
#This refers to example 1 (significant correlation) is handout 7.4
# To check whether there are significant correlation between predictor variables, we use the cor() functions and pass only the predictor variables
require(knitr)
kable(cor(ReducedColTrain[ ,2:5]), digits = 3, caption = "Correlation Between Predictors")
```

### We see that (as expected) the 'medIncome' and 'PctPrivateCoverage' have a pretty high positive correlation with r values of 0.77 close to 1. So multicollinearity exists in the dataset and we need to drop one of these predictors. We can do that by creating separate models with one of those variables at the time and compering their respective AIC values, where smaller AIC is preferred.

```{r, echo = x}
#Model without 'medIncome'
testModel1 = lm(Traincancer_data$TARGET_deathRate ~ Traincancer_data$AvgHouseholdSize +            Traincancer_data$PctPrivateCoverage + Traincancer_data$incidenceRate, data = Traincancer_data)
#Model without 'PctPrivateCoverage'
testModel2 = lm(Traincancer_data$TARGET_deathRate ~ Traincancer_data$AvgHouseholdSize +     Traincancer_data$incidenceRate + Traincancer_data$medIncome, data = Traincancer_data)
print("AIC for model without 'medIncome' , followed by 'PctPrivateCoverage' ")
AIC(testModel1)
AIC(testModel2)
summary(testModel1)
print(" **************************************************************** ")
summary(testModel2)
```
### AIC in testModel2, the one without the'PctPrivateCoverage' predictor variable, is smaller than AIC of testModel1, so we drop the 'PctPrivateCoverage' variable in the model


## 2. Opposite signs in parameter estimates than what is expected
```{r, echo = x}
#####################################################################################################
#Do we need this part here since we have already performed the correlation test between variables?
#####################################################################################################
```

## 3. Using  the Variance Inflaction Factor, VIF.
###We want VIF values less than 10 for each predictor variable.
###At this point we have already discarded 'PctPrivateCoverage', but we want to make sure to check again the model by performing the VIF test
```{r, echo = x}
#We are going to use the testModel we use in the prior chunk. This is the new model without 'PctPrivateCoverage'
#install the car package which has the VIF function.

#Load the car package
require(car)
#To get the VIF values we need to pass the model into the vif() function
kable(cbind(c("AvgHouseholdSize","incidenceRate","medIncome"), round(vif(testModel2),3)), digits = 3, row.names = 0, col.names = c("Predictors", "VIF"), align = "l")
```
###It looks like everything is good now, the VIF's are very low, we can say that now we have a dataset free from correlation between predictor variables.